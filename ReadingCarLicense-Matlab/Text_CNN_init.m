function net = TextorNot_CNN_init()

rng('default');
rng(0);

f = 1/100;
%my net
net.layers = {};
net.layers{end+1} = struct('type','conv',...
                           'weights',{{f*randn(5,5,1,120,'single'),zeros(1,120,'single')}},...
                           'stride',1,...
                           'pad',0);
net.layers{end+1} = struct('type','relu');
net.layers{end+1} = struct('type','pool',...
                           'method', 'max', ...
                          'pool',[4 4],...
                          'stride',4,...
                          'pad',0);
net.layers{end+1} = struct('type','conv',...
                          'weights',{{f*randn(2,2,120,384,'single'),zeros(1,384,'single')}},...
                          'stride',1,...
                          'pad',0);
net.layers{end+1} = struct('type','relu');
net.layers{end+1} = struct('type','pool',...
                           'method', 'max', ...
                          'pool',[2 2],...
                          'stride',2,...
                          'pad',0);
net.layers{end+1} = struct('type','conv',...
                           'weights',{{f*randn(2,2,384,512,'single'), zeros(1,512,'single')}},...
                           'stride',1,...
                           'pad',0);
net.layers{end+1} = struct('type','relu');
net.layers{end+1} = struct('type','dropout','rate',0.5);
net.layers{end+1} = struct('type','conv',...
                           'weights',{{f*randn(1,1,512,65,'single'),zeros(1,65,'single')}},...
                           'stride',1,...
                           'pad',0);
net.layers{end+1} = struct('type','softmaxloss');


%example net
% net.layers = {};
% net.layers{end+1} = struct('type', 'conv', ...
%                            'weights', {{f*randn(3,3,1,20, 'single'), zeros(1, 20, 'single')}}, ...
%                            'stride', 1, ...
%                            'pad', 0) ; %randn���վ�ֵΪ0������Ϊ1����̬�ֲ����������
% net.layers{end+1} = struct('type', 'relu') ;
% net.layers{end+1} = struct('type', 'pool', ...
%                            'method', 'max', ...
%                            'pool', [2 2], ...
%                            'stride', 2, ...
%                            'pad', 0) ;
% net.layers{end+1} = struct('type', 'conv', ...
%                            'weights', {{f*randn(3,3,20,100, 'single'),zeros(1,100,'single')}}, ...
%                            'stride', 1, ...
%                            'pad', 0) ;
% net.layers{end+1} = struct('type', 'relu') ;
% net.layers{end+1} = struct('type', 'pool', ...
%                            'method', 'max', ...
%                            'pool', [2 2], ...
%                            'stride', 2, ...
%                            'pad', 0) ;
% net.layers{end+1} = struct('type', 'conv', ...
%                            'weights', {{f*randn(1,1,100,100, 'single'),zeros(1,100,'single')}}, ...
%                            'stride', 1, ...
%                            'pad', 0) ;                       
% net.layers{end+1} = struct('type', 'relu') ;
% net.layers{end+1} = struct('type','dropout','rate',0.5);
% net.layers{end+1} = struct('type', 'conv', ...
%                            'weights', {{f*randn(3,3,100,1000, 'single'),zeros(1,1000,'single')}}, ...
%                            'stride', 1, ...
%                            'pad', 0) ;
% net.layers{end+1} = struct('type', 'softmaxloss') ;

%mate parameters
net.meta.inputSize = [24 24 1];
net.meta.trainOpts.learningRate = logspace(-3, -5, 100);
net.meta.trainOpts.numEpochs = 300;
net.meta.trainOpts.batchSize = 1000;

%fill in default values

net = vl_simplenn_tidy(net);
end




